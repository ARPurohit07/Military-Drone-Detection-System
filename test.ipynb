{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5687a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abb04f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "TURKISH_IMG_PATH = \"Turkish\"\n",
    "TURKISH_LABEL_PATH = \"labels_turkish\"\n",
    "CHINESE_IMG_PATH = \"Chinese\"\n",
    "CHINESE_LABEL_PATH = \"labels_chinese\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6a58f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def load_dataset(image_folder, label_folder, subclass_label, blur_prob=0.3, distort_prob=0.3, augment_copies=2, debug=False):\n",
    "    X, y_drone, y_subclass = [], [], []\n",
    "\n",
    "    for fname in tqdm(os.listdir(image_folder)):\n",
    "        if not fname.lower().endswith(('.jpg', '.png')):\n",
    "            continue\n",
    "\n",
    "        image_path = os.path.join(image_folder, fname)\n",
    "        label_path = os.path.join(label_folder, os.path.splitext(fname)[0] + \".txt\")\n",
    "\n",
    "        img_original = cv2.imread(image_path)\n",
    "        if img_original is None:\n",
    "            continue\n",
    "        img_original = cv2.resize(img_original, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "        # ========== Process Original Image ==========\n",
    "        img = img_original.astype(\"float32\") / 255.0\n",
    "        label = 0\n",
    "        subclass = 0 if subclass_label == \"turkish\" else 1\n",
    "\n",
    "        if not os.path.exists(label_path):\n",
    "            label = 1\n",
    "            subclass = 2\n",
    "        else:\n",
    "            with open(label_path, 'r') as f:\n",
    "                if len(f.readlines()) == 0:\n",
    "                    label = 1\n",
    "                    subclass = 2\n",
    "\n",
    "        X.append(img)\n",
    "        y_drone.append(label)\n",
    "        y_subclass.append(subclass)\n",
    "\n",
    "        # ========== Augment and Save Copies ==========\n",
    "        base_name = os.path.splitext(fname)[0]\n",
    "        ext = os.path.splitext(fname)[1]\n",
    "\n",
    "        for i in range(augment_copies):\n",
    "            aug_img = img_original.copy()\n",
    "\n",
    "            # Apply blur\n",
    "            if random.random() < blur_prob:\n",
    "                aug_img = cv2.GaussianBlur(aug_img, (5, 5), 0)\n",
    "\n",
    "            # Apply brightness/contrast\n",
    "            if random.random() < distort_prob:\n",
    "                alpha = 1.0 + np.random.uniform(-0.3, 0.3)\n",
    "                beta = np.random.randint(-30, 30)\n",
    "                aug_img = cv2.convertScaleAbs(aug_img, alpha=alpha, beta=beta)\n",
    "\n",
    "            aug_img = cv2.resize(aug_img, (IMG_SIZE, IMG_SIZE))\n",
    "            aug_img_float = aug_img.astype(\"float32\") / 255.0\n",
    "\n",
    "            # Save augmented image\n",
    "            aug_fname = f\"{base_name}_aug{i}{ext}\"\n",
    "            aug_img_path = os.path.join(image_folder, aug_fname)\n",
    "            cv2.imwrite(aug_img_path, aug_img)\n",
    "\n",
    "            # Copy label file with same content\n",
    "            if os.path.exists(label_path):\n",
    "                aug_label_path = os.path.join(label_folder, f\"{base_name}_aug{i}.txt\")\n",
    "                shutil.copyfile(label_path, aug_label_path)\n",
    "\n",
    "            # Store in arrays\n",
    "            X.append(aug_img_float)\n",
    "            y_drone.append(label)\n",
    "            y_subclass.append(subclass)\n",
    "\n",
    "            if debug:\n",
    "                plt.imshow(cv2.cvtColor(aug_img, cv2.COLOR_BGR2RGB))\n",
    "                plt.title(f\"Augmented Saved: {aug_fname}\")\n",
    "                plt.axis(\"off\")\n",
    "                plt.show()\n",
    "\n",
    "    return np.array(X), np.array(y_drone), np.array(y_subclass)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c52eb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 902/902 [00:13<00:00, 69.05it/s]\n",
      "100%|██████████| 1272/1272 [00:17<00:00, 71.35it/s]\n"
     ]
    }
   ],
   "source": [
    "X_turkish, y_drone_turkish, y_subclass_turkish = load_dataset(TURKISH_IMG_PATH, TURKISH_LABEL_PATH, \"turkish\")\n",
    "X_chinese, y_drone_chinese, y_subclass_chinese = load_dataset(CHINESE_IMG_PATH, CHINESE_LABEL_PATH, \"chinese\")\n",
    "\n",
    "X = np.concatenate([X_turkish, X_chinese])\n",
    "y_drone = np.concatenate([y_drone_turkish, y_drone_chinese])\n",
    "y_subclass = np.concatenate([y_subclass_turkish, y_subclass_chinese])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0298cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_subclass = np.where(y_subclass == 2, 0, y_subclass)\n",
    "y_subclass_cat = to_categorical(y_subclass, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "397e2695",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_drone_train, y_drone_val, y_sub_train, y_sub_val = train_test_split(\n",
    "    X, y_drone, y_subclass_cat, test_size=0.2, stratify=y_drone, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6388c505",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "x = Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "drone_output = Dense(1, activation='sigmoid', name='drone_output')(x)\n",
    "subclass_output = Dense(2, activation='softmax', name='subclass_output')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=[drone_output, subclass_output])\n",
    "model.compile(\n",
    "    optimizer=Adam(1e-4),\n",
    "    loss={'drone_output': 'binary_crossentropy', 'subclass_output': 'categorical_crossentropy'},\n",
    "    metrics={'drone_output': 'accuracy', 'subclass_output': 'accuracy'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade03e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 133ms/step - drone_output_accuracy: 0.9880 - drone_output_loss: 0.0745 - loss: 0.7551 - subclass_output_accuracy: 0.5962 - subclass_output_loss: 0.6806 - val_drone_output_accuracy: 0.9946 - val_drone_output_loss: 0.0223 - val_loss: 0.5572 - val_subclass_output_accuracy: 0.7440 - val_subclass_output_loss: 0.5351\n",
      "Epoch 2/25\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 129ms/step - drone_output_accuracy: 0.9962 - drone_output_loss: 0.0218 - loss: 0.5038 - subclass_output_accuracy: 0.7762 - subclass_output_loss: 0.4820 - val_drone_output_accuracy: 0.9984 - val_drone_output_loss: 0.0174 - val_loss: 0.4444 - val_subclass_output_accuracy: 0.8084 - val_subclass_output_loss: 0.4272\n",
      "Epoch 3/25\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 129ms/step - drone_output_accuracy: 0.9968 - drone_output_loss: 0.0093 - loss: 0.3869 - subclass_output_accuracy: 0.8334 - subclass_output_loss: 0.3776 - val_drone_output_accuracy: 0.9984 - val_drone_output_loss: 0.0035 - val_loss: 0.3619 - val_subclass_output_accuracy: 0.8278 - val_subclass_output_loss: 0.3588\n",
      "Epoch 4/25\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 139ms/step - drone_output_accuracy: 0.9996 - drone_output_loss: 0.0023 - loss: 0.3185 - subclass_output_accuracy: 0.8599 - subclass_output_loss: 0.3161 - val_drone_output_accuracy: 1.0000 - val_drone_output_loss: 9.9174e-04 - val_loss: 0.3151 - val_subclass_output_accuracy: 0.8410 - val_subclass_output_loss: 0.3140\n",
      "Epoch 5/25\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 129ms/step - drone_output_accuracy: 1.0000 - drone_output_loss: 0.0012 - loss: 0.2941 - subclass_output_accuracy: 0.8600 - subclass_output_loss: 0.2929 - val_drone_output_accuracy: 1.0000 - val_drone_output_loss: 8.1939e-04 - val_loss: 0.2932 - val_subclass_output_accuracy: 0.8479 - val_subclass_output_loss: 0.2922\n",
      "Epoch 6/25\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 130ms/step - drone_output_accuracy: 1.0000 - drone_output_loss: 8.0091e-04 - loss: 0.2505 - subclass_output_accuracy: 0.8799 - subclass_output_loss: 0.2497 - val_drone_output_accuracy: 1.0000 - val_drone_output_loss: 4.4660e-04 - val_loss: 0.2882 - val_subclass_output_accuracy: 0.8472 - val_subclass_output_loss: 0.2873\n",
      "Epoch 7/25\n",
      "\u001b[1m322/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - drone_output_accuracy: 1.0000 - drone_output_loss: 0.0010 - loss: 0.2645 - subclass_output_accuracy: 0.8656 - subclass_output_loss: 0.2634"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    {'drone_output': y_drone_train, 'subclass_output': y_sub_train},\n",
    "    validation_data=(X_val, {'drone_output': y_drone_val, 'subclass_output': y_sub_val}),\n",
    "    epochs=25,\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "model.save(\"drone_classifier_Aug.h5\")\n",
    "print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d06e63ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "IMG_SIZE = 224  # Use same size as training\n",
    "\n",
    "model = load_model(\"drone_classifier_Aug.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6771fe50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Could not read image: {image_path}\")\n",
    "    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "    img = img.astype(\"float32\") / 255.0\n",
    "    img = np.expand_dims(img, axis=0)  # shape: (1, 224, 224, 3)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69bd61ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image_path):\n",
    "    img = preprocess_image(image_path)\n",
    "\n",
    "    # Get both outputs\n",
    "    preds = model.predict(img)\n",
    "    drone_pred = preds[0][0][0]  # output from 'drone_output'\n",
    "    subclass_probs = preds[1][0]  # output from 'subclass_output'\n",
    "\n",
    "    if drone_pred < 0.5:\n",
    "        print(f\"🛑 Not a Drone (score: {drone_pred:.2f})\")\n",
    "    else:\n",
    "        subclass = np.argmax(subclass_probs)\n",
    "        subclass_label = \"Turkish\" if subclass == 0 else \"Chinese\"\n",
    "        print(f\"✅ Drone Detected (score: {drone_pred:.2f}) — Subclass: {subclass_label} (conf: {subclass_probs[subclass]:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51917032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "🛑 Not a Drone (score: 0.00)\n"
     ]
    }
   ],
   "source": [
    "predict_image(\"Turkish\\\\turkish_0199_aug0_aug0.jpg\")\n",
    "#predict_image(\"Chinese/sample_china.jpg\")\n",
    "#predict_image(\"non_drones/random_object.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7291565",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
